{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7cf089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in Predicted Median (over 100 iterations): 12.18 months\n",
      "Average Error in Predicted Mean (over 100 iterations): 7.70 months\n",
      "Average beta (k) over 100 iterations: 1.56\n",
      "Average alpha over 100 iterations: 132.26\n",
      "Overall Median Survival Time (Weibull-based): 104.64 months\n",
      "Overall Mean Survival Time (Weibull-based): 118.83 months\n",
      "Overall Mean Survival Time (from dataset): 125.48 months\n",
      "Overall Median Survival Time (from dataset): 116.53 months\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z0/8ts7jcs15f184f9f8lfbtb3w0000gn/T/ipykernel_23917/1619861818.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  term3 = (beta - 1) * np.sum(np.log(data))\n",
      "/Users/weiqi/anaconda3/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "from scipy.special import gamma  # Import the gamma function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "file_path = 'Breast Cancer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assume the survival time column is 'Overall Survival (Months)'\n",
    "survival_time = data['Overall Survival (Months)'].dropna().values\n",
    "\n",
    "# Define the maximum likelihood estimation objective function using Weibull distribution log-likelihood\n",
    "def mle_weibull(params, data):\n",
    "    beta, alpha = params\n",
    "    n = len(data)\n",
    "    \n",
    "    # Weibull log-likelihood function based on MLE theory\n",
    "    term1 = n * np.log(beta)\n",
    "    term2 = -n * beta * np.log(alpha)\n",
    "    term3 = (beta - 1) * np.sum(np.log(data))\n",
    "    term4 = -np.sum((data / alpha) ** beta)\n",
    "    \n",
    "    log_likelihood = term1 + term2 + term3 + term4\n",
    "    \n",
    "    return -log_likelihood  # Return negative for minimization\n",
    "\n",
    "# Function to estimate parameters and calculate errors\n",
    "def estimate_and_calculate_errors(train_data, test_data):\n",
    "    # Initial guess values\n",
    "    initial_params = [1.5, np.mean(train_data)]  # Initialize beta and alpha\n",
    "\n",
    "    # Use numerical optimization to find the best parameter estimates on training data\n",
    "    result = opt.minimize(mle_weibull, initial_params, args=(train_data), method='L-BFGS-B', bounds=[(0.01, None), (0.01, None)])\n",
    "    \n",
    "    beta_mle, alpha_mle = result.x\n",
    "\n",
    "    # Calculate the predicted median and mean based on the estimated parameters\n",
    "    median_survival_pred = alpha_mle * (np.log(2)) ** (1 / beta_mle)\n",
    "    mean_survival_pred = alpha_mle * gamma(1 + 1 / beta_mle)\n",
    "\n",
    "    # Calculate the actual median and mean for the test set\n",
    "    median_survival_test = np.median(test_data)\n",
    "    mean_survival_test = np.mean(test_data)\n",
    "\n",
    "    # Calculate the errors in the predicted values for the test set\n",
    "    median_error = np.abs(median_survival_pred - median_survival_test)\n",
    "    mean_error = np.abs(mean_survival_pred - mean_survival_test)\n",
    "\n",
    "    return beta_mle, alpha_mle, median_error, mean_error\n",
    "\n",
    "# Initialize lists to store errors and parameters\n",
    "median_errors = []\n",
    "mean_errors = []\n",
    "beta_values = []\n",
    "alpha_values = []\n",
    "\n",
    "# Run the process 100 times\n",
    "for i in range(100):\n",
    "    # Split the data into training and testing sets (50% each)\n",
    "    train_data, test_data = train_test_split(survival_time, test_size=0.5)\n",
    "\n",
    "    # Estimate parameters and calculate errors\n",
    "    beta_mle, alpha_mle, median_error, mean_error = estimate_and_calculate_errors(train_data, test_data)\n",
    "\n",
    "    # Append the errors and parameters to the lists\n",
    "    beta_values.append(beta_mle)\n",
    "    alpha_values.append(alpha_mle)\n",
    "    median_errors.append(median_error)\n",
    "    mean_errors.append(mean_error)\n",
    "\n",
    "# Calculate the average errors, average beta and alpha values\n",
    "average_median_error = np.mean(median_errors)\n",
    "average_mean_error = np.mean(mean_errors)\n",
    "average_beta = np.mean(beta_values)\n",
    "average_alpha = np.mean(alpha_values)\n",
    "\n",
    "# Calculate the overall mean and median based on the average parameters\n",
    "overall_median = average_alpha * (np.log(2)) ** (1 / average_beta)\n",
    "overall_mean = average_alpha * gamma(1 + 1 / average_beta)\n",
    "\n",
    "# Calculate the mean and median for the overall dataset (survival_time)\n",
    "overall_survival_mean = np.mean(survival_time)\n",
    "overall_survival_median = np.median(survival_time)\n",
    "\n",
    "# Print the average errors, parameters, and overall median and mean\n",
    "print(f\"Average Error in Predicted Median (over 100 iterations): {average_median_error:.2f} months\")\n",
    "print(f\"Average Error in Predicted Mean (over 100 iterations): {average_mean_error:.2f} months\")\n",
    "print(f\"Average beta (k) over 100 iterations: {average_beta:.2f}\")\n",
    "print(f\"Average alpha over 100 iterations: {average_alpha:.2f}\")\n",
    "print(f\"Overall Median Survival Time (Weibull-based): {overall_median:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (Weibull-based): {overall_mean:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (from dataset): {overall_survival_mean:.2f} months\")\n",
    "print(f\"Overall Median Survival Time (from dataset): {overall_survival_median:.2f} months\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4939b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z0/8ts7jcs15f184f9f8lfbtb3w0000gn/T/ipykernel_23917/4082833823.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  term3 = (beta - 1) * np.sum(np.log(data))\n",
      "/Users/weiqi/anaconda3/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in Predicted Median (over 1000 iterations): 11.59 months\n",
      "Average Error in Predicted Mean (over 1000 iterations): 7.34 months\n",
      "Average Error in beta (k) over 1000 iterations: 0.07\n",
      "Average Error in alpha over 1000 iterations: 6.85\n",
      "Average beta (k) over 1000 iterations: 1.57\n",
      "Average alpha over 1000 iterations: 132.76\n",
      "Overall Median Survival Time (Weibull-based): 105.10 months\n",
      "Overall Mean Survival Time (Weibull-based): 119.26 months\n",
      "Overall Mean Survival Time (from dataset): 125.48 months\n",
      "Overall Median Survival Time (from dataset): 116.53 months\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "from scipy.special import gamma  # Import the gamma function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "file_path = 'Breast Cancer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assume the survival time column is 'Overall Survival (Months)'\n",
    "survival_time = data['Overall Survival (Months)'].dropna().values\n",
    "\n",
    "# Define the maximum likelihood estimation objective function using Weibull distribution log-likelihood\n",
    "def mle_weibull(params, data):\n",
    "    beta, alpha = params\n",
    "    n = len(data)\n",
    "    \n",
    "    # Weibull log-likelihood function based on MLE theory\n",
    "    term1 = n * np.log(beta)\n",
    "    term2 = -n * beta * np.log(alpha)\n",
    "    term3 = (beta - 1) * np.sum(np.log(data))\n",
    "    term4 = -np.sum((data / alpha) ** beta)\n",
    "    \n",
    "    log_likelihood = term1 + term2 + term3 + term4\n",
    "    \n",
    "    return -log_likelihood  # Return negative for minimization\n",
    "\n",
    "# Function to estimate parameters and calculate errors\n",
    "def estimate_and_calculate_errors(train_data, test_data):\n",
    "    # Initial guess values\n",
    "    initial_params = [1.5, np.mean(train_data)]  # Initialize beta and alpha\n",
    "\n",
    "    # Use numerical optimization to find the best parameter estimates on training data\n",
    "    result = opt.minimize(mle_weibull, initial_params, args=(train_data), method='L-BFGS-B', bounds=[(0.01, None), (0.01, None)])\n",
    "    \n",
    "    beta_mle, alpha_mle = result.x\n",
    "\n",
    "    # Calculate the predicted median and mean based on the estimated parameters\n",
    "    median_survival_pred = alpha_mle * (np.log(2)) ** (1 / beta_mle)\n",
    "    mean_survival_pred = alpha_mle * gamma(1 + 1 / beta_mle)\n",
    "\n",
    "    # Calculate the actual median and mean for the test set\n",
    "    median_survival_test = np.median(test_data)\n",
    "    mean_survival_test = np.mean(test_data)\n",
    "\n",
    "    # Calculate the errors in the predicted values for the test set\n",
    "    median_error = np.abs(median_survival_pred - median_survival_test)\n",
    "    mean_error = np.abs(mean_survival_pred - mean_survival_test)\n",
    "\n",
    "    # Calculate the errors in alpha and beta\n",
    "    # For the test set, recalculate the parameters using the MLE method\n",
    "    result_test = opt.minimize(mle_weibull, [beta_mle, alpha_mle], args=(test_data), method='L-BFGS-B', bounds=[(0.01, None), (0.01, None)])\n",
    "    beta_test, alpha_test = result_test.x\n",
    "    \n",
    "    alpha_error = np.abs(alpha_mle - alpha_test)\n",
    "    beta_error = np.abs(beta_mle - beta_test)\n",
    "\n",
    "    return beta_mle, alpha_mle, beta_error, alpha_error, median_error, mean_error\n",
    "\n",
    "# Initialize lists to store errors and parameters\n",
    "median_errors = []\n",
    "mean_errors = []\n",
    "beta_values = []\n",
    "alpha_values = []\n",
    "beta_errors = []\n",
    "alpha_errors = []\n",
    "\n",
    "# Run the process 1000 times\n",
    "for i in range(1000):\n",
    "    # Split the data into training and testing sets (50% each)\n",
    "    train_data, test_data = train_test_split(survival_time, test_size=0.5)\n",
    "\n",
    "    # Estimate parameters and calculate errors\n",
    "    beta_mle, alpha_mle, beta_error, alpha_error, median_error, mean_error = estimate_and_calculate_errors(train_data, test_data)\n",
    "\n",
    "    # Append the errors and parameters to the lists\n",
    "    beta_values.append(beta_mle)\n",
    "    alpha_values.append(alpha_mle)\n",
    "    beta_errors.append(beta_error)\n",
    "    alpha_errors.append(alpha_error)\n",
    "    median_errors.append(median_error)\n",
    "    mean_errors.append(mean_error)\n",
    "\n",
    "# Calculate the average errors, average beta, and alpha values\n",
    "average_median_error = np.mean(median_errors)\n",
    "average_mean_error = np.mean(mean_errors)\n",
    "average_beta = np.mean(beta_values)\n",
    "average_alpha = np.mean(alpha_values)\n",
    "average_beta_error = np.mean(beta_errors)\n",
    "average_alpha_error = np.mean(alpha_errors)\n",
    "\n",
    "# Calculate the overall mean and median based on the average parameters\n",
    "overall_median = average_alpha * (np.log(2)) ** (1 / average_beta)\n",
    "overall_mean = average_alpha * gamma(1 + 1 / average_beta)\n",
    "\n",
    "# Calculate the mean and median for the overall dataset (survival_time)\n",
    "overall_survival_mean = np.mean(survival_time)\n",
    "overall_survival_median = np.median(survival_time)\n",
    "\n",
    "# Print the average errors, parameters, and overall median and mean\n",
    "print(f\"Average Error in Predicted Median (over 1000 iterations): {average_median_error:.2f} months\")\n",
    "print(f\"Average Error in Predicted Mean (over 1000 iterations): {average_mean_error:.2f} months\")\n",
    "print(f\"Average Error in beta (k) over 1000 iterations: {average_beta_error:.2f}\")\n",
    "print(f\"Average Error in alpha over 1000 iterations: {average_alpha_error:.2f}\")\n",
    "print(f\"Average beta (k) over 1000 iterations: {average_beta:.2f}\")\n",
    "print(f\"Average alpha over 1000 iterations: {average_alpha:.2f}\")\n",
    "print(f\"Overall Median Survival Time (Weibull-based): {overall_median:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (Weibull-based): {overall_mean:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (from dataset): {overall_survival_mean:.2f} months\")\n",
    "print(f\"Overall Median Survival Time (from dataset): {overall_survival_median:.2f} months\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da49412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in Predicted Median (over 100 iterations): 4.22 months\n",
      "Average Error in Predicted Mean (over 100 iterations): 8.35 months\n",
      "Average k (shape parameter) over 100 iterations: 1.50\n",
      "Average alpha (scale parameter) over 100 iterations: 148.37\n",
      "Overall Median Survival Time (Weibull-based): 116.23 months\n",
      "Overall Mean Survival Time (Weibull-based): 133.92 months\n",
      "Overall Mean Survival Time (from dataset): 125.48 months\n",
      "Overall Median Survival Time (from dataset): 116.53 months\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import gamma, gammainc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data (replace with actual breast cancer survival data)\n",
    "file_path = 'Breast Cancer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assume the survival time column is 'Overall Survival (Months)'\n",
    "survival_time = data['Overall Survival (Months)'].dropna().values\n",
    "\n",
    "\n",
    "\n",
    "# Define the MAD function using the provided formula\n",
    "def mad_weibull(alpha, k):\n",
    "    log2_1k = (np.log(2))**(1/k)\n",
    "    term1 = log2_1k\n",
    "    term2 = (1/k) * gamma(1/k)\n",
    "    term3 = (2/k) * gammainc(1/k, np.log(2))\n",
    "    mad = alpha * (term1 - term2 + term3)\n",
    "    return mad\n",
    "\n",
    "# Calculate the MAD to Median Ratio using the formula\n",
    "def mad_to_median_ratio(k):\n",
    "    log2_1k = (np.log(2))**(1/k)\n",
    "    gamma_1k = gamma(1/k)\n",
    "    incomplete_gamma_1k_log2 = gammainc(1/k, np.log(2))\n",
    "    ratio = 1 - (1 / (k * log2_1k)) * (gamma_1k + 2 * incomplete_gamma_1k_log2)\n",
    "    return ratio\n",
    "\n",
    "# Function to estimate parameters and calculate errors\n",
    "def estimate_and_calculate_errors(train_data, test_data):\n",
    "    # Step 1: Calculate the Median (M) and 75th Percentile (Q3) from training data\n",
    "    M = np.median(train_data)  # Median\n",
    "    Q3 = np.percentile(train_data, 75)  # 75th percentile (Third quantile)\n",
    "\n",
    "    # Step 2: Estimate k using the formula: k = log(2) / (log(Q3) - log(M))\n",
    "    k = np.log(2) / (np.log(Q3) - np.log(M))\n",
    "\n",
    "    # Step 3: Estimate alpha using the formula: alpha = M / (log(2))^(1/k)\n",
    "    alpha = M / (np.log(2))**(1/k)\n",
    "\n",
    "    # Step 4: Calculate predicted median and mean using Weibull parameters\n",
    "    median_pred = alpha * (np.log(2))**(1/k)\n",
    "    mean_pred = alpha * gamma(1 + 1/k)\n",
    "\n",
    "    # Step 5: Calculate the actual median and mean for the test set\n",
    "    median_actual = np.median(test_data)\n",
    "    mean_actual = np.mean(test_data)\n",
    "\n",
    "    # Step 6: Calculate errors in predicted values for the test set\n",
    "    median_error = np.abs(median_pred - median_actual)\n",
    "    mean_error = np.abs(mean_pred - mean_actual)\n",
    "\n",
    "    return k, alpha, median_error, mean_error, median_pred, mean_pred\n",
    "\n",
    "# Initialize lists to store errors and parameters\n",
    "median_errors = []\n",
    "mean_errors = []\n",
    "k_values = []\n",
    "alpha_values = []\n",
    "median_predictions = []\n",
    "mean_predictions = []\n",
    "\n",
    "# Run the process 100 times\n",
    "for i in range(100):\n",
    "    # Split the data into training and testing sets (50% each)\n",
    "    train_data, test_data = train_test_split(survival_time, test_size=0.5)\n",
    "\n",
    "    # Estimate parameters and calculate errors\n",
    "    k, alpha, median_error, mean_error, median_pred, mean_pred = estimate_and_calculate_errors(train_data, test_data)\n",
    "\n",
    "    # Append the errors and parameters to the lists\n",
    "    k_values.append(k)\n",
    "    alpha_values.append(alpha)\n",
    "    median_errors.append(median_error)\n",
    "    mean_errors.append(mean_error)\n",
    "    median_predictions.append(median_pred)\n",
    "    mean_predictions.append(mean_pred)\n",
    "\n",
    "# Calculate average errors and parameters over 100 iterations\n",
    "average_median_error = np.mean(median_errors)\n",
    "average_mean_error = np.mean(mean_errors)\n",
    "average_k = np.mean(k_values)\n",
    "average_alpha = np.mean(alpha_values)\n",
    "\n",
    "# Calculate overall median and mean survival times based on the average Weibull parameters\n",
    "overall_median_weibull = average_alpha * (np.log(2))**(1 / average_k)\n",
    "overall_mean_weibull = average_alpha * gamma(1 + 1 / average_k)\n",
    "\n",
    "# Calculate the actual mean and median survival times from the entire dataset\n",
    "overall_survival_mean = np.mean(survival_time)\n",
    "overall_survival_median = np.median(survival_time)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Error in Predicted Median (over 100 iterations): {average_median_error:.2f} months\")\n",
    "print(f\"Average Error in Predicted Mean (over 100 iterations): {average_mean_error:.2f} months\")\n",
    "print(f\"Average k (shape parameter) over 100 iterations: {average_k:.2f}\")\n",
    "print(f\"Average alpha (scale parameter) over 100 iterations: {average_alpha:.2f}\")\n",
    "print(f\"Overall Median Survival Time (Weibull-based): {overall_median_weibull:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (Weibull-based): {overall_mean_weibull:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (from dataset): {overall_survival_mean:.2f} months\")\n",
    "print(f\"Overall Median Survival Time (from dataset): {overall_survival_median:.2f} months\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffecf62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in k (over 1000 iterations): 0.09\n",
      "Average Error in alpha (over 1000 iterations): 3.72\n",
      "Average Error in Predicted Median (over 1000 iterations): 3.93 months\n",
      "Average Error in Predicted Mean (over 1000 iterations): 8.71 months\n",
      "Average k (shape parameter) over 1000 iterations: 1.51\n",
      "Average alpha (scale parameter) over 1000 iterations: 148.67\n",
      "Overall Median Survival Time (Weibull-based): 116.56 months\n",
      "Overall Mean Survival Time (Weibull-based): 134.19 months\n",
      "Overall Mean Survival Time (from dataset): 125.48 months\n",
      "Overall Median Survival Time (from dataset): 116.53 months\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import gamma, gammainc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data (replace with actual breast cancer survival data)\n",
    "file_path = 'Breast Cancer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assume the survival time column is 'Overall Survival (Months)'\n",
    "survival_time = data['Overall Survival (Months)'].dropna().values\n",
    "\n",
    "# Define the MAD function using the provided formula\n",
    "def mad_weibull(alpha, k):\n",
    "    log2_1k = (np.log(2))**(1/k)\n",
    "    term1 = log2_1k\n",
    "    term2 = (1/k) * gamma(1/k)\n",
    "    term3 = (2/k) * gammainc(1/k, np.log(2))\n",
    "    mad = alpha * (term1 - term2 + term3)\n",
    "    return mad\n",
    "\n",
    "# Calculate the MAD to Median Ratio using the formula\n",
    "def mad_to_median_ratio(k):\n",
    "    log2_1k = (np.log(2))**(1/k)\n",
    "    gamma_1k = gamma(1/k)\n",
    "    incomplete_gamma_1k_log2 = gammainc(1/k, np.log(2))\n",
    "    ratio = 1 - (1 / (k * log2_1k)) * (gamma_1k + 2 * incomplete_gamma_1k_log2)\n",
    "    return ratio\n",
    "\n",
    "# Function to estimate parameters and calculate errors\n",
    "def estimate_and_calculate_errors(train_data, test_data):\n",
    "    # Step 1: Calculate the Median (M) and 75th Percentile (Q3) from training data\n",
    "    M_train = np.median(train_data)  # Median\n",
    "    Q3_train = np.percentile(train_data, 75)  # 75th percentile (Third quantile)\n",
    "    \n",
    "    # Step 2: Estimate k using the formula: k = log(2) / (log(Q3) - log(M))\n",
    "    k_train = np.log(2) / (np.log(Q3_train) - np.log(M_train))\n",
    "\n",
    "    # Step 3: Estimate alpha using the formula: alpha = M / (log(2))^(1/k)\n",
    "    alpha_train = M_train / (np.log(2))**(1/k_train)\n",
    "\n",
    "    # Step 4: Calculate the actual median and 75th percentile for the test set\n",
    "    M_test = np.median(test_data)\n",
    "    Q3_test = np.percentile(test_data, 75)\n",
    "    \n",
    "    # Estimate k and alpha for the test set\n",
    "    k_test = np.log(2) / (np.log(Q3_test) - np.log(M_test))\n",
    "    alpha_test = M_test / (np.log(2))**(1/k_test)\n",
    "    \n",
    "    # Step 5: Calculate errors in k and alpha between train and test sets\n",
    "    k_error = np.abs(k_train - k_test)\n",
    "    alpha_error = np.abs(alpha_train - alpha_test)\n",
    "\n",
    "    # Step 6: Calculate predicted median and mean using Weibull parameters for train set\n",
    "    median_pred_train = alpha_train * (np.log(2))**(1/k_train)\n",
    "    mean_pred_train = alpha_train * gamma(1 + 1/k_train)\n",
    "\n",
    "    # Step 7: Calculate actual median and mean for the test set\n",
    "    median_actual_test = np.median(test_data)\n",
    "    mean_actual_test = np.mean(test_data)\n",
    "\n",
    "    # Step 8: Calculate errors in predicted values for the test set\n",
    "    median_error = np.abs(median_pred_train - median_actual_test)\n",
    "    mean_error = np.abs(mean_pred_train - mean_actual_test)\n",
    "\n",
    "    return k_train, alpha_train, k_error, alpha_error, median_error, mean_error\n",
    "\n",
    "# Initialize lists to store errors and parameters\n",
    "k_train_values = []\n",
    "alpha_train_values = []\n",
    "k_errors = []\n",
    "alpha_errors = []\n",
    "median_errors = []\n",
    "mean_errors = []\n",
    "\n",
    "# Initialize lists for original results (overall values)\n",
    "k_values = []\n",
    "alpha_values = []\n",
    "median_predictions = []\n",
    "mean_predictions = []\n",
    "\n",
    "# Run the process 1000 times\n",
    "for i in range(1000):\n",
    "    # Split the data into training and testing sets (50% each)\n",
    "    train_data, test_data = train_test_split(survival_time, test_size=0.5)\n",
    "\n",
    "    # Estimate parameters and calculate errors\n",
    "    k_train, alpha_train, k_error, alpha_error, median_error, mean_error = estimate_and_calculate_errors(train_data, test_data)\n",
    "\n",
    "    # Append the errors and parameters to the lists for error calculations\n",
    "    k_train_values.append(k_train)\n",
    "    alpha_train_values.append(alpha_train)\n",
    "    k_errors.append(k_error)\n",
    "    alpha_errors.append(alpha_error)\n",
    "    median_errors.append(median_error)\n",
    "    mean_errors.append(mean_error)\n",
    "\n",
    "    # Append the original values for overall analysis\n",
    "    k_values.append(k_train)\n",
    "    alpha_values.append(alpha_train)\n",
    "    median_predictions.append(alpha_train * (np.log(2))**(1/k_train))\n",
    "    mean_predictions.append(alpha_train * gamma(1 + 1/k_train))\n",
    "\n",
    "# Calculate average errors and parameters over 100 iterations\n",
    "average_k_error = np.mean(k_errors)\n",
    "average_alpha_error = np.mean(alpha_errors)\n",
    "average_median_error = np.mean(median_errors)\n",
    "average_mean_error = np.mean(mean_errors)\n",
    "average_k_train = np.mean(k_train_values)\n",
    "average_alpha_train = np.mean(alpha_train_values)\n",
    "\n",
    "# Calculate overall averages (for original Weibull-based results)\n",
    "average_k = np.mean(k_values)\n",
    "average_alpha = np.mean(alpha_values)\n",
    "overall_median_weibull = np.mean(median_predictions)\n",
    "overall_mean_weibull = np.mean(mean_predictions)\n",
    "\n",
    "# Calculate the actual mean and median survival times from the entire dataset\n",
    "overall_survival_mean = np.mean(survival_time)\n",
    "overall_survival_median = np.median(survival_time)\n",
    "\n",
    "# Print the additional k and alpha error results\n",
    "print(f\"Average Error in k (over 1000 iterations): {average_k_error:.2f}\")\n",
    "print(f\"Average Error in alpha (over 1000 iterations): {average_alpha_error:.2f}\")\n",
    "\n",
    "# Print the original results\n",
    "print(f\"Average Error in Predicted Median (over 1000 iterations): {average_median_error:.2f} months\")\n",
    "print(f\"Average Error in Predicted Mean (over 1000 iterations): {average_mean_error:.2f} months\")\n",
    "print(f\"Average k (shape parameter) over 1000 iterations: {average_k:.2f}\")\n",
    "print(f\"Average alpha (scale parameter) over 1000 iterations: {average_alpha:.2f}\")\n",
    "print(f\"Overall Median Survival Time (Weibull-based): {overall_median_weibull:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (Weibull-based): {overall_mean_weibull:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (from dataset): {overall_survival_mean:.2f} months\")\n",
    "print(f\"Overall Median Survival Time (from dataset): {overall_survival_median:.2f} months\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0593547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in k (over 1000 iterations): 0.09\n",
      "Average Error in alpha (over 1000 iterations): 3.83\n",
      "Average Error in Predicted Median (over 1000 iterations): 4.22 months\n",
      "Average Error in Predicted Mean (over 1000 iterations): 8.94 months\n",
      "Average k (shape parameter) over 1000 iterations: 1.51\n",
      "Average alpha (scale parameter) over 1000 iterations: 148.83\n",
      "Overall Median Survival Time (Weibull-based): 116.68 months\n",
      "Overall Mean Survival Time (Weibull-based): 134.33 months\n",
      "Overall Mean Survival Time (from dataset): 125.48 months\n",
      "Overall Median Survival Time (from dataset): 116.53 months\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import gamma\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data (replace with actual breast cancer survival data)\n",
    "file_path = 'Breast Cancer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assume the survival time column is 'Overall Survival (Months)'\n",
    "survival_time = data['Overall Survival (Months)'].dropna().values\n",
    "\n",
    "# Function to estimate Weibull parameters using quantiles\n",
    "def quantile_weibull(train_data, test_data):\n",
    "    # Step 1: Calculate the median (M) and 75th percentile (Q3) from the training data\n",
    "    M_train = np.median(train_data)  # Median\n",
    "    Q3_train = np.percentile(train_data, 75)  # Third quartile (75th percentile)\n",
    "\n",
    "    # Step 2: Estimate k using the formula: k = log(2) / (log(Q3) - log(M))\n",
    "    k_train = np.log(2) / (np.log(Q3_train) - np.log(M_train))\n",
    "\n",
    "    # Step 3: Estimate alpha using the formula: alpha = M / (log(2))^(1/k)\n",
    "    alpha_train = M_train / (np.log(2))**(1/k_train)\n",
    "\n",
    "    # Step 4: Calculate the actual median and 75th percentile for the test set\n",
    "    M_test = np.median(test_data)\n",
    "    Q3_test = np.percentile(test_data, 75)\n",
    "\n",
    "    # Estimate k and alpha for the test set\n",
    "    k_test = np.log(2) / (np.log(Q3_test) - np.log(M_test))\n",
    "    alpha_test = M_test / (np.log(2))**(1/k_test)\n",
    "\n",
    "    # Step 5: Calculate errors between train and test sets for k and alpha\n",
    "    k_error = np.abs(k_train - k_test)\n",
    "    alpha_error = np.abs(alpha_train - alpha_test)\n",
    "\n",
    "    # Step 6: Calculate the predicted median and mean using Weibull parameters for the train set\n",
    "    median_pred_train = alpha_train * (np.log(2))**(1/k_train)\n",
    "    mean_pred_train = alpha_train * gamma(1 + 1/k_train)\n",
    "\n",
    "    # Step 7: Calculate actual median and mean for the test set\n",
    "    median_actual_test = np.median(test_data)\n",
    "    mean_actual_test = np.mean(test_data)\n",
    "\n",
    "    # Step 8: Calculate errors in predicted median and mean for the test set\n",
    "    median_error = np.abs(median_pred_train - median_actual_test)\n",
    "    mean_error = np.abs(mean_pred_train - mean_actual_test)\n",
    "\n",
    "    return k_train, alpha_train, k_error, alpha_error, median_error, mean_error\n",
    "\n",
    "# Initialize lists to store errors and parameters\n",
    "k_train_values = []\n",
    "alpha_train_values = []\n",
    "k_errors = []\n",
    "alpha_errors = []\n",
    "median_errors = []\n",
    "mean_errors = []\n",
    "\n",
    "# Initialize lists for original results (overall values)\n",
    "k_values = []\n",
    "alpha_values = []\n",
    "median_predictions = []\n",
    "mean_predictions = []\n",
    "\n",
    "# Run the process 1000 times\n",
    "for i in range(1000):\n",
    "    # Split the data into training and testing sets (50% each)\n",
    "    train_data, test_data = train_test_split(survival_time, test_size=0.5)\n",
    "\n",
    "    # Estimate parameters and calculate errors\n",
    "    k_train, alpha_train, k_error, alpha_error, median_error, mean_error = quantile_weibull(train_data, test_data)\n",
    "\n",
    "    # Append errors and parameters to the lists\n",
    "    k_train_values.append(k_train)\n",
    "    alpha_train_values.append(alpha_train)\n",
    "    k_errors.append(k_error)\n",
    "    alpha_errors.append(alpha_error)\n",
    "    median_errors.append(median_error)\n",
    "    mean_errors.append(mean_error)\n",
    "\n",
    "    # Append original values for overall analysis\n",
    "    k_values.append(k_train)\n",
    "    alpha_values.append(alpha_train)\n",
    "    median_predictions.append(alpha_train * (np.log(2))**(1/k_train))\n",
    "    mean_predictions.append(alpha_train * gamma(1 + 1/k_train))\n",
    "\n",
    "# Calculate average errors and parameters over 1000 iterations\n",
    "average_k_error = np.mean(k_errors)\n",
    "average_alpha_error = np.mean(alpha_errors)\n",
    "average_median_error = np.mean(median_errors)\n",
    "average_mean_error = np.mean(mean_errors)\n",
    "average_k_train = np.mean(k_train_values)\n",
    "average_alpha_train = np.mean(alpha_train_values)\n",
    "\n",
    "# Calculate overall averages (for original Weibull-based results)\n",
    "average_k = np.mean(k_values)\n",
    "average_alpha = np.mean(alpha_values)\n",
    "overall_median_weibull = np.mean(median_predictions)\n",
    "overall_mean_weibull = np.mean(mean_predictions)\n",
    "\n",
    "# Calculate the actual mean and median survival times from the entire dataset\n",
    "overall_survival_mean = np.mean(survival_time)\n",
    "overall_survival_median = np.median(survival_time)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Error in k (over 1000 iterations): {average_k_error:.2f}\")\n",
    "print(f\"Average Error in alpha (over 1000 iterations): {average_alpha_error:.2f}\")\n",
    "print(f\"Average Error in Predicted Median (over 1000 iterations): {average_median_error:.2f} months\")\n",
    "print(f\"Average Error in Predicted Mean (over 1000 iterations): {average_mean_error:.2f} months\")\n",
    "print(f\"Average k (shape parameter) over 1000 iterations: {average_k:.2f}\")\n",
    "print(f\"Average alpha (scale parameter) over 1000 iterations: {average_alpha:.2f}\")\n",
    "print(f\"Overall Median Survival Time (Weibull-based): {overall_median_weibull:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (Weibull-based): {overall_mean_weibull:.2f} months\")\n",
    "print(f\"Overall Mean Survival Time (from dataset): {overall_survival_mean:.2f} months\")\n",
    "print(f\"Overall Median Survival Time (from dataset): {overall_survival_median:.2f} months\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b108dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
